{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Intro-to-Pytorch\" data-toc-modified-id=\"Intro-to-Pytorch-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Intro to Pytorch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pytorch-tensors\" data-toc-modified-id=\"Pytorch-tensors-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Pytorch tensors</a></span></li><li><span><a href=\"#Pytorch-Autograd\" data-toc-modified-id=\"Pytorch-Autograd-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Pytorch Autograd</a></span></li><li><span><a href=\"#torch.nn-module\" data-toc-modified-id=\"torch.nn-module-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>torch.nn module</a></span></li></ul></li><li><span><a href=\"#Linear-Regression-with-Pytorch\" data-toc-modified-id=\"Linear-Regression-with-Pytorch-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Linear Regression with Pytorch</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gradient-Descent-with-Pytorch\" data-toc-modified-id=\"Gradient-Descent-with-Pytorch-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Gradient Descent with Pytorch</a></span></li><li><span><a href=\"#Simplified-GD-Loop\" data-toc-modified-id=\"Simplified-GD-Loop-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Simplified GD Loop</a></span><ul class=\"toc-item\"><li><span><a href=\"#Models-in-Pytorch\" data-toc-modified-id=\"Models-in-Pytorch-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Models in Pytorch</a></span></li></ul></li></ul></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Logistic Regression</a></span><ul class=\"toc-item\"><li><span><a href=\"#How-to-take-a-vector-back-to-numpy?\" data-toc-modified-id=\"How-to-take-a-vector-back-to-numpy?-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>How to take a vector back to numpy?</a></span></li><li><span><a href=\"#Exercise:\" data-toc-modified-id=\"Exercise:-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Exercise:</a></span></li></ul></li><li><span><a href=\"#References\" data-toc-modified-id=\"References-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>References</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pytorch libraries\n",
    "%matplotlib inline\n",
    "import torch \n",
    "import torch.autograd as autograd \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch consists of 4 main packages:\n",
    "* torch: a general purpose array library similar to Numpy that can do computations on GPU\n",
    "* torch.autograd: a package for automatically obtaining gradients\n",
    "* torch.nn: a neural net library with common layers and cost functions\n",
    "* torch.optim: an optimization package with common optimization algorithms like SGD, Adam, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch tensors\n",
    "Like Numpy tensors but can utilize GPUs to accelerate its numerical computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating tensors from lists or numpy arrays\n",
    "x = torch.tensor([[1, 2],[3, 4]])\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create random tensor\n",
    "N = 5\n",
    "x = torch.randn(N, 10).type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3883,  1.2063, -1.8117, -0.0942, -1.4076,  0.5117,  1.2906,  0.8324,\n",
       "          1.1340, -0.4395],\n",
       "        [ 0.9606,  0.3571,  0.7962, -1.4168,  0.0091,  1.7742, -0.7495, -0.7344,\n",
       "          2.0811,  2.3594],\n",
       "        [ 0.8729,  0.2959,  1.5066, -0.9544, -0.5578, -0.3215, -1.9424, -0.1705,\n",
       "          0.1012,  0.4498],\n",
       "        [-0.2209,  0.3269,  1.1722,  0.0893,  0.3265, -0.5602, -0.2444, -0.3539,\n",
       "         -0.7230,  0.1117],\n",
       "        [ 0.3641, -0.3506, -0.5746, -1.5101,  0.5176,  0.8828, -1.0791,  0.5406,\n",
       "          0.2212,  0.3888]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3883,  1.2063, -1.8117, -0.0942, -1.4076,  0.5117,  1.2906,  0.8324,\n",
       "          1.1340, -0.4395,  0.9606,  0.3571,  0.7962, -1.4168,  0.0091,  1.7742,\n",
       "         -0.7495, -0.7344,  2.0811,  2.3594,  0.8729,  0.2959,  1.5066, -0.9544,\n",
       "         -0.5578, -0.3215, -1.9424, -0.1705,  0.1012,  0.4498, -0.2209,  0.3269,\n",
       "          1.1722,  0.0893,  0.3265, -0.5602, -0.2444, -0.3539, -0.7230,  0.1117,\n",
       "          0.3641, -0.3506, -0.5746, -1.5101,  0.5176,  0.8828, -1.0791,  0.5406,\n",
       "          0.2212,  0.3888]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping of tensors using .view()\n",
    "x.view(1,-1) #-1 makes torch infer the second dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch Autograd\n",
    "The autograd package in PyTorch provides classes and functions implementing automatic differentiation of arbitrary scalar valued function. For example, the gradient of the error with respect to all parameters.\n",
    "\n",
    "In order for this to happen we need to declare our paramerers as Tensors with the requires_grad=True keyword. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([1., 2., 3., 4., 5., 6.], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  9., 19., 33., 51., 73.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*x**2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(188., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = (2*x**2 +1).sum()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "L.backward() # computes the grad of L with respect to x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.,  8., 12., 16., 20., 24.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1008, -0.4600, -0.8994],\n",
       "        [ 0.2201,  0.6536, -0.7497]], requires_grad=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is another example\n",
    "x = torch.randn(2, 3)\n",
    "x.requires_grad = True\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0684, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = (x**2).sum()\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2016, -0.9200, -1.7989],\n",
       "        [ 0.4402,  1.3071, -1.4994]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.backward()\n",
    "x.grad # note, it is the same shape as x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## torch.nn module\n",
    "A neural net library with common layers and cost functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nn.Linear(5, 3)` creates a linear transformation ($A\\cdot X+b$) of a $N \\times 5$ matrix into a $N \\times 3$ matrix, where N can be anything (number of observations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 5 # number of input featutes\n",
    "M = 3 # neurons in the first hidden layer\n",
    "linear_map = nn.Linear(D, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.2191, -0.4431, -0.2171, -0.1346,  0.3015],\n",
       "         [-0.3180,  0.3449, -0.2812, -0.1371,  0.0263],\n",
       "         [-0.4074,  0.2542, -0.3986, -0.3842, -0.1838]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.3270,  0.4079, -0.2412], requires_grad=True)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parameters are initialized randomly\n",
    "[p for p in linear_map.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([3, 5]), torch.Size([3])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p.shape for p in linear_map.parameters()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Linear Regression with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of linear regression is to fit a line to a set of points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we generate some fake data\n",
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_fake_data(n, a, b):\n",
    "    x = np.random.uniform(0,1,n) \n",
    "    y = lin(a,b,x) + 0.1 * np.random.normal(0,3,n)\n",
    "    return x, y\n",
    "\n",
    "x, y = gen_fake_data(50, 3., 8.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x,y, s=8); plt.xlabel(\"x\"); plt.ylabel(\"y\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to find **parameters** (weights) $a$ and $b$ such that you minimize the *error* between the points and the line $a\\cdot x + b$. Note that here $a$ and $b$ are unknown. For a regression problem the most common *error function* or *loss function* is the **mean squared error** ($\\sum_i (\\hat{y}_i - y_i)^2$). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_hat, y): return ((y_hat - y) ** 2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we believe $a = 10$ and $b = 5$ then we can compute `y_hat` which is our *prediction* and then compute our error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.408392788545063"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = lin(10,5,x)\n",
    "mse(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(a, b, x, y): return mse(lin(a,b,x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.408392788545063"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_loss(10, 5, x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have specified the *model* (linear regression) and the *evaluation criteria* (or *loss function*). Now we need to handle *optimization*; that is, how do we find the best values for $a$ and $b$? How do we find the best *fitting* linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a fixed dataset $x$ and $y$ `mse_loss(a,b)` is a function of $a$ and $b$. We would like to find the values of $a$ and $b$ that minimize that function.\n",
    "\n",
    "**Gradient descent** is an algorithm that minimizes functions. Given a function defined by a set of parameters, gradient descent starts with an initial set of parameter values and iteratively moves toward a set of parameter values that minimize the function. This iterative minimization is achieved by taking steps in the negative direction of the function gradient.\n",
    "\n",
    "Here is gradient descent implemented in [PyTorch](http://pytorch.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate some more data\n",
    "x, y = gen_fake_data(10000, 3., 8.)\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap x and y as tensor \n",
    "x = torch.tensor(x)\n",
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9061], dtype=torch.float64, requires_grad=True),\n",
       " tensor([1.0029], dtype=torch.float64, requires_grad=True))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random Tensors for weights, and wrap them in tensors.\n",
    "# Setting requires_grad=True indicates that we want to compute gradients with\n",
    "# respect to these tensors during the backward pass.\n",
    "a, b = np.random.randn(1), np.random.randn(1)\n",
    "a = torch.tensor(a, requires_grad=True)\n",
    "b = torch.tensor(b, requires_grad=True)\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.083316289312\n",
      "0.6037559029568478\n",
      "0.17452341128611484\n",
      "0.15281493247322975\n",
      "0.1380948350376663\n",
      "0.12681776598903674\n",
      "0.1181692099985105\n",
      "0.11153644298727595\n",
      "0.10644962833239727\n",
      "0.1025484384814155\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    loss = mse_loss(a,b,x,y)\n",
    "    if t % 1000 == 0: print(loss.item())\n",
    "    \n",
    "    # Computes the gradient of loss with respect to all Variables with requires_grad=True.\n",
    "    # After this call a.grad and b.grad will be Variables holding the gradient\n",
    "    # of the loss with respect to a and b respectively\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update a and b using gradient descent; a.data and b.data are Tensors,\n",
    "    # a.grad and b.grad are Variables and a.grad.data and b.grad.data are Tensors\n",
    "    a.data -= learning_rate * a.grad.data\n",
    "    b.data -= learning_rate * b.grad.data\n",
    "    \n",
    "    # Zero the gradients\n",
    "    a.grad.data.zero_()\n",
    "    b.grad.data.zero_()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.3365], dtype=torch.float64, requires_grad=True) tensor([7.8181], dtype=torch.float64, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplified GD Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=1, out_features=1, bias=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear tranformation with input dimension=1 and output dimension=1\n",
    "nn.Linear(1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models in Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple way of specifying a linear regression model\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(1, 1),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equivalent way of specifiying the same model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.lin = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.lin(x)\n",
    "        return x \n",
    "model =  LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.5986]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.5310], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "# note here we have just two parameters, why?\n",
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = gen_fake_data(10000, 3., 8.)\n",
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float()\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you have to be careful with the dimensions that your model is expecting\n",
    "x = torch.unsqueeze(x, 1)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1623],\n",
      "        [-0.2239],\n",
      "        [-0.3763],\n",
      "        ...,\n",
      "        [-0.1297],\n",
      "        [-0.0414],\n",
      "        [-0.3819]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_hat = model(x)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 1])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(95.4309, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = y.unsqueeze(1)\n",
    "F.mse_loss(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation data\n",
    "x_val, y_val = gen_fake_data(1000, 3., 8.)\n",
    "x_val = torch.tensor(x_val).float().unsqueeze(1)\n",
    "y_val = torch.tensor(y_val).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the optim package to define an Optimizer that will update the \n",
    "# weights of\n",
    "# the model for us. Here we will use Adam\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 95.431 valid loss 93.120\n",
      "train loss 0.110 valid loss 0.105\n",
      "train loss 0.096 valid loss 0.092\n",
      "train loss 0.092 valid loss 0.089\n",
      "train loss 0.091 valid loss 0.088\n",
      "train loss 0.091 valid loss 0.088\n",
      "train loss 0.091 valid loss 0.088\n",
      "train loss 0.090 valid loss 0.088\n",
      "train loss 0.090 valid loss 0.088\n",
      "train loss 0.090 valid loss 0.088\n"
     ]
    }
   ],
   "source": [
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    model.train() # some layers have different behavior during train/and evaluation\n",
    "    y_hat = model(x)\n",
    "    loss = F.mse_loss(y_hat, y)\n",
    "       \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    # checking validation loss\n",
    "    model.eval()  # some layers have different behavior during train/and evaluation\n",
    "    y_hat_val = model(x_val)\n",
    "    val_loss = F.mse_loss(y_hat_val, y_val)\n",
    "    \n",
    "    if t % 1000 == 0: print(\"train loss %.3f valid loss %.3f\" % (loss.item(), val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[2.9917]], requires_grad=True), Parameter containing:\n",
      "tensor([8.0074], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating fake data\n",
    "# Here we generate some fake data\n",
    "def lin(a,b,x): return a*x+b\n",
    "\n",
    "def gen_logistic_fake_data(n, a, b):\n",
    "    x = np.random.uniform(-20,20, (n, 2))\n",
    "    x2_hat = lin(a,b, x[:,0])\n",
    "    y = x[:,1] > x2_hat\n",
    "    return x, y.astype(int)\n",
    "\n",
    "x, y = gen_logistic_fake_data(100, 1., 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f98205dfb20>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.arange(-20, 20, 0.2)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x[:,0],x[:,1],c=y, s=8);\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\");\n",
    "plt.plot(t, t + 0.5, 'r--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2, 1),\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating train and val data\n",
    "x, y = gen_logistic_fake_data(10000, 1., 0.5)\n",
    "x = torch.tensor(x).float()\n",
    "y = torch.tensor(y).float().unsqueeze(1)\n",
    "\n",
    "x_val, y_val = gen_logistic_fake_data(1000, 1., 0.5)\n",
    "x_val = torch.tensor(x_val).float()\n",
    "y_val = torch.tensor(y_val).float().unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 0.274 valid loss 0.169\n",
      "train loss 0.009 valid loss 0.011\n",
      "train loss 0.007 valid loss 0.009\n",
      "train loss 0.006 valid loss 0.008\n",
      "train loss 0.005 valid loss 0.007\n",
      "train loss 0.004 valid loss 0.006\n",
      "train loss 0.003 valid loss 0.005\n",
      "train loss 0.003 valid loss 0.004\n",
      "train loss 0.003 valid loss 0.005\n",
      "train loss 0.003 valid loss 0.004\n"
     ]
    }
   ],
   "source": [
    "for t in range(10000):\n",
    "    # Forward pass: compute predicted y using operations on Variables\n",
    "    model.train()\n",
    "    y_hat = model(x)\n",
    "    loss = F.binary_cross_entropy(torch.sigmoid(y_hat), y)\n",
    "       \n",
    "    # Before the backward pass, use the optimizer object to zero all of the\n",
    "    # gradients for the variables\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()\n",
    "    \n",
    "    model.eval()\n",
    "    y_hat_val = model(x_val)\n",
    "    val_loss = F.binary_cross_entropy(torch.sigmoid(y_hat_val), y_val)\n",
    "    \n",
    "    if t % 1000 == 0: print(\"train loss %.3f valid loss %.3f\" % (loss.item(), val_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-11.6385,  11.6529]], requires_grad=True), Parameter containing:\n",
      "tensor([-5.8426], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print([p for p in model.parameters()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to take a vector back to numpy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = gen_logistic_fake_data(10, 1., 0.5)\n",
    "x = torch.tensor(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.1703018e+01, -1.2524307e+01],\n",
       "       [-1.8268692e+01, -1.7967501e+01],\n",
       "       [-1.2290472e+01, -1.8407137e+01],\n",
       "       [ 1.9503149e+01,  5.3839850e+00],\n",
       "       [-1.3441429e+01,  1.0874328e+01],\n",
       "       [ 1.3799089e-02, -9.2699766e+00],\n",
       "       [ 1.4474929e+01,  5.1685233e+00],\n",
       "       [ 1.0985559e+01, -5.7011991e+00],\n",
       "       [ 4.6939769e+00, -9.1349974e+00],\n",
       "       [-4.4303374e+00,  1.2479983e+01]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "Compute the accuracy of the validation logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need more?\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/basics/intro.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# References\n",
    "* https://pytorch.org/docs/stable/index.html\n",
    "* http://pytorch.org/tutorials/beginner/pytorch_with_examples.html\n",
    "* https://hsaghir.github.io/data_science/pytorch_starter/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nav_menu": {},
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "116px",
    "width": "251px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
